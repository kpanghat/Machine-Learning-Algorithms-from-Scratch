{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "d3c2641f"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "85f5ae6c"
   },
   "outputs": [],
   "source": [
    "# random dataset with n = 1000 (# of data points) and d = 2 (# of dimensions)\n",
    "x1= np.random.randint(2, size = 1000)\n",
    "x2= np.random.randint(2, size = 1000)\n",
    "y= np.random.randint(2, size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "3380617d"
   },
   "outputs": [],
   "source": [
    "X= np.vstack((x1,x2)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "c54c0a51"
   },
   "outputs": [],
   "source": [
    "class NaiveBayes: \n",
    "    \n",
    "    def __init__(self, X, y,t):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        \n",
    "    def splitData(self):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = 0.3, random_state = 15)\n",
    "           \n",
    "    def probability(self, X, prior, dist1, dist2):\n",
    "        return prior * dist1 * dist2\n",
    "\n",
    "    def computeLiklihoodArrayForCol(self,series):\n",
    "        liklihood_probability_dict = {}\n",
    "        liklihood_numerator_dict = {}\n",
    "        liklihood_denominator_dict = {}\n",
    "        for unique_value in series.unique():\n",
    "            liklihood_numerator_dict[unique_value] = (series[series == unique_value].shape[0])\n",
    "            liklihood_denominator_dict[unique_value] = series.shape[0]\n",
    "            liklihood_probability_dict[unique_value] = (series[series == unique_value].shape[0])/series.shape[0]\n",
    "        return liklihood_numerator_dict,liklihood_denominator_dict,liklihood_probability_dict\n",
    "\n",
    "\n",
    "    ## FOR LAPLACE SMOOTHING WILL HAVE TO STORE THE NUMERATORS\n",
    "    def computeLiklihoodArrayForColSmoothing(self,series):\n",
    "        liklihood_dict ={}\n",
    "        for unique_value in series.unique():\n",
    "            liklihood_dict[unique_value] = (series[series == unique_value].shape[0])/series.shape[0]\n",
    "        return liklihood_dict\n",
    "    \n",
    "    ## Liklihoods are stored in a dictionary of arrays of dictionary\n",
    "    ## key of dict is target category. For each target category we have a array of length = number of columns\n",
    "    ## For each index of this array we have a dictionary. key for this inner dictionary is column category and value is liklihood of seeing that category for that column given target category\n",
    "    ## A similiar data structure is maintained for storing numerators and denominators. Storing numerators and denominators are necesary for doing Laplace smoothing\n",
    "    def printLiklihoods(self):\n",
    "        targetCategories = list(self.dictOfLiklihoods.keys())\n",
    "        for unique_value in targetCategories:\n",
    "            for col_index in range(self.X_train.shape[1]):\n",
    "                colLiklihoodDict = self.dictOfLiklihoods[unique_value][col_index]\n",
    "                for colCategory in list(colLiklihoodDict.keys()):\n",
    "                    print('Liklihood of column {} having {} given target category {} is : {}'.format(col_index+1,colCategory,unique_value,colLiklihoodDict[colCategory]))\n",
    "\n",
    "    def fit(self):\n",
    "        self.splitData()\n",
    "        target = pd.Series(self.y_train)\n",
    "        self.prior_dict = {}\n",
    "        for unique_value in target.unique():\n",
    "            self.prior_dict[unique_value] = (target[target == unique_value].shape[0])/target.shape[0]\n",
    "        for unique_value in target.unique():\n",
    "            print('Prior probability for seeing {} is : {}'.format(unique_value,self.prior_dict[unique_value]))\n",
    "        cols = ['X_' + str(i) for i in range(self.X_train.shape[1])]\n",
    "        predictors = pd.DataFrame(self.X_train,columns=cols)\n",
    "        self.dictOfLiklihoodsNumerator = {}\n",
    "        self.dictOfLiklihoodsDenominator = {}\n",
    "        self.dictOfLiklihoods = {}\n",
    "        for unique_value in target.unique():\n",
    "            liklihoods = []\n",
    "            numeratorLiklihood = []\n",
    "            denominatorLiklihood = []\n",
    "            for col in cols:\n",
    "                liklihood_numerator,lilkilhood_denominator,liklihood_probability = self.computeLiklihoodArrayForCol(predictors.loc[target == unique_value,col])\n",
    "                numeratorLiklihood.append(liklihood_numerator)\n",
    "                denominatorLiklihood.append(lilkilhood_denominator)\n",
    "                liklihoods.append(liklihood_probability)\n",
    "            self.dictOfLiklihoodsNumerator[unique_value] = numeratorLiklihood\n",
    "            self.dictOfLiklihoodsDenominator[unique_value] = denominatorLiklihood\n",
    "            self.dictOfLiklihoods[unique_value] = liklihoods\n",
    "        self.printLiklihoods()\n",
    "    \n",
    "    def isNewCategory(self,col_index,colCategory):\n",
    "        targetCategories = list(self.dictOfLiklihoods.keys())\n",
    "        for category in targetCategories:\n",
    "            if self.dictOfLiklihoods[category][col_index].get(colCategory,-1) != -1:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def predict(self,X):\n",
    "        targetCategories = list(self.dictOfLiklihoods.keys())\n",
    "        predictions = []\n",
    "        for i in range(X.shape[0]):\n",
    "            testPoint = X[i,:]\n",
    "            listLogProbabilities = []\n",
    "            for category in targetCategories:\n",
    "                logProbability = 0\n",
    "                liklihoods = self.dictOfLiklihoods[category]\n",
    "                for index in range(len(liklihoods)):\n",
    "                    if self.isNewCategory(index,testPoint[index]):\n",
    "                        self.laplaceSmoothing(index,testPoint[index])\n",
    "                        print('{} is a new category for column {}. Hence we are doing Laplace Smoothing.'.format(testPoint[index],index+1))\n",
    "                        print('Liklihoods after Lapace Smoothing are as follows:')\n",
    "                        self.printLiklihoods()\n",
    "                    if liklihoods[index].get(testPoint[index],-1) != -1:\n",
    "                        logProbability += np.log(liklihoods[index][testPoint[index]])\n",
    "                logProbability += np.log(self.prior_dict[category])\n",
    "                listLogProbabilities.append(logProbability)\n",
    "            predictionCateoryIndex = np.argmax(listLogProbabilities)\n",
    "            predictions.append(targetCategories[predictionCateoryIndex])\n",
    "        return predictions\n",
    "\n",
    "    def laplaceSmoothing(self,col_index,newColCategory):\n",
    "        targetCategories = list(self.dictOfLiklihoods.keys())\n",
    "        t = self.t\n",
    "        for category in targetCategories:\n",
    "            denominator = 1\n",
    "            catgoriesInCol = list(self.dictOfLiklihoodsNumerator[category][col_index].keys())\n",
    "            for colCategory in catgoriesInCol:\n",
    "                newNumerator = self.dictOfLiklihoodsNumerator[category][col_index][colCategory] + t\n",
    "                newDenominator = self.dictOfLiklihoodsDenominator[category][col_index][colCategory] + (len(catgoriesInCol)+1)*t\n",
    "                denominator = newDenominator\n",
    "                self.dictOfLiklihoodsNumerator[category][col_index][colCategory] = newNumerator\n",
    "                self.dictOfLiklihoodsDenominator[category][col_index][colCategory] = newDenominator\n",
    "                self.dictOfLiklihoods[category][col_index][colCategory] = newNumerator/newDenominator\n",
    "            self.dictOfLiklihoodsNumerator[category][col_index][newColCategory] = t\n",
    "            self.dictOfLiklihoodsDenominator[category][col_index][newColCategory] = denominator\n",
    "            self.dictOfLiklihoods[category][col_index][newColCategory] = t/denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "ac3901e4"
   },
   "outputs": [],
   "source": [
    "clf = NaiveBayes(X, y,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "H-yuLVGjSVZk"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "ebfda0a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability for seeing 1 is : 0.5028571428571429\n",
      "Prior probability for seeing 0 is : 0.49714285714285716\n",
      "Liklihood of column 1 having 0 given target category 1 is : 0.48295454545454547\n",
      "Liklihood of column 1 having 1 given target category 1 is : 0.5170454545454546\n",
      "Liklihood of column 2 having 0 given target category 1 is : 0.5227272727272727\n",
      "Liklihood of column 2 having 1 given target category 1 is : 0.4772727272727273\n",
      "Liklihood of column 1 having 0 given target category 0 is : 0.5373563218390804\n",
      "Liklihood of column 1 having 1 given target category 0 is : 0.46264367816091956\n",
      "Liklihood of column 2 having 0 given target category 0 is : 0.45689655172413796\n",
      "Liklihood of column 2 having 1 given target category 0 is : 0.5431034482758621\n"
     ]
    }
   ],
   "source": [
    "clf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyAi7ubtvJKh",
    "outputId": "b47c93ce-b8de-49df-c441-e2a35cb249ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "335a1f61"
   },
   "source": [
    "### Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 is a new category for column 2. Hence we are doing Laplace Smoothing.\n",
      "Liklihoods after Lapace Smoothing are as follows:\n",
      "Liklihood of column 1 having 0 given target category 1 is : 0.48295454545454547\n",
      "Liklihood of column 1 having 1 given target category 1 is : 0.5170454545454546\n",
      "Liklihood of column 2 having 0 given target category 1 is : 0.49514563106796117\n",
      "Liklihood of column 2 having 1 given target category 1 is : 0.4563106796116505\n",
      "Liklihood of column 2 having 2 given target category 1 is : 0.04854368932038835\n",
      "Liklihood of column 1 having 0 given target category 0 is : 0.5373563218390804\n",
      "Liklihood of column 1 having 1 given target category 0 is : 0.46264367816091956\n",
      "Liklihood of column 2 having 0 given target category 0 is : 0.4387254901960784\n",
      "Liklihood of column 2 having 1 given target category 0 is : 0.5122549019607843\n",
      "Liklihood of column 2 having 2 given target category 0 is : 0.049019607843137254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.array([[1,2],[0,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
